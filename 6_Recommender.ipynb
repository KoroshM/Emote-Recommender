{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook version of the recommender for testing. Implementation here will differ from the actual recommender file, Recommender.py\n",
    "\n",
    "Make sure you update the model path if necessary in Recommender.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.word2vec\n",
    "import numpy as np\n",
    "\n",
    "model_dir = r\"PATH\\TO\\MODELS\\MODEL_NAME\\model\" # ex: C:\\Emote_Recommender\\models\\twitch_500_20e\\model\n",
    "\n",
    "model = gensim.models.word2vec.Word2Vec.load(model_dir)\n",
    "embeddings = model.wv\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .Tokenizer import TwitchTokenizer\n",
    "\n",
    "tokenizer = TwitchTokenizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load registered Emotes\n",
    "with open('emote_dict', 'rb') as f:\n",
    "    emotes = pickle.load(f)\n",
    "    emotes.replace(['NaN', 'nan'], np.nan, inplace = True)\n",
    "\n",
    "with open('bttv_dict', 'rb') as f:\n",
    "    bttv_emotes = pickle.load(f)\n",
    "    bttv_emotes.replace(['NaN', 'nan'], np.nan, inplace = True)\n",
    "\n",
    "with open('ffz_dict', 'rb') as f:\n",
    "    ffz_emotes = pickle.load(f).T\n",
    "    ffz_emotes.replace(['NaN', 'nan'], np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_twitch = ['GLOBAL_TWITCH']\n",
    "base_twitch.extend([\n",
    "    'GLOBAL_FFZ',\n",
    "    'GLOBAL_7TV'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel the user is currently chatting in\n",
    "channel = 'HasanAbi'\n",
    "\n",
    "# Channels the user is actively subscribed to\n",
    "subs = [\n",
    "    'CohhCarnage',\n",
    "    'xQc',\n",
    "    'pokimane'\n",
    "]\n",
    "twitch_subs = subs.copy()\n",
    "twitch_subs.extend(base_twitch)\n",
    "\n",
    "# Emotes native to the current channel\n",
    "emotes_ch = [x for x in emotes[channel].fillna('').values.flatten() if x != '']\n",
    "\n",
    "# Emotes the user has access to\n",
    "emotes_user = [x for x in emotes[twitch_subs].fillna('').values.flatten() if x != '']\n",
    "\n",
    "# Handle BTTV\n",
    "bttv_subs = subs.copy()\n",
    "bttv_subs.extend(['GLOBAL_BTTV'])        \n",
    "emotes_ch.extend([x for x in bttv_emotes[channel].fillna('').values.flatten() if x != ''])\n",
    "emotes_user.extend([x for x in bttv_emotes[bttv_subs].fillna('').values.flatten() if x != ''])\n",
    "\n",
    "# Handle FFZ\n",
    "ffz_subs = subs.copy()\n",
    "base_twitch.extend(['GLOBAL_FFZ'])\n",
    "if channel in ffz_emotes.columns: # Less channel support on FFZ than BTTV\n",
    "    emotes_ch.extend([x for x in ffz_emotes[channel].fillna('').values.flatten() if x != ''])\n",
    "    emotes_user.extend([x for x in ffz_emotes[ffz_subs].fillna('').values.flatten() if x != ''])\n",
    "\n",
    "# All relevant emotes for lookup\n",
    "emotes_all = emotes_ch + emotes_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendEmotes(msg: str) -> list:\n",
    "    \"\"\"\n",
    "    Returns a dict of the most similar emotes for each emote found in input.\n",
    "\n",
    "    Param: msg - chat message as a string\n",
    "    Param: subs - list of channels the user is subscribed to\n",
    "    Param: channel - current channel the msg is being sent in\n",
    "    Return: dict with detected emotes and the 3 most similar in 'channel'\n",
    "    \"\"\"\n",
    "    rec = dict()\n",
    "    tok = tokenizer.tokenize(text=msg,emotes=emotes_all)    \n",
    "\n",
    "    # For each word in the chat message\n",
    "    for token in tok:\n",
    "        if token not in emotes_all:\n",
    "            # Emote from unrecognized channel (or just text)\n",
    "            continue\n",
    "\n",
    "        # Calculate similarity between the current emote and each emote in the current channel\n",
    "        sim_scores = {}\n",
    "        for emote in emotes_ch:\n",
    "            try:\n",
    "                sim_scores[emote] = embeddings.similarity(token.lower(), emote.lower())\n",
    "            except Exception as e:\n",
    "                # No embedding data found for an emote\n",
    "                # Either embeddings are out of date or emote just isn't used enough\n",
    "                continue\n",
    "            \n",
    "        # Sort by similarity and return top 3 emotes\n",
    "        sim_scores = sorted(sim_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        rec[token] = [emote for emote in sim_scores[:3]]\n",
    "\n",
    "    # Return a dict of detected emotes as keys with recommendations as values\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"AYAYA here's a haHAA chat message forsenPls good luck cohhLUL remember to sub <3\" # Example message from user to process\n",
    "\n",
    "rec_emotes = recommendEmotes(msg=msg)\n",
    "rec_emotes # Print the detected emotes in the message and their most similar emotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite user's message with new emotes for the current channel\n",
    "new_msg = msg\n",
    "for emote in rec_emotes.items():\n",
    "    if len(emote[1]) > 0:\n",
    "        new_msg = new_msg.replace(emote[0],emote[1][0][0])\n",
    "\n",
    "new_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find which channels an emote is registered to (can be multiple channels for emotes from 3rd party extensions)\n",
    "def find_channel(emote: str):\n",
    "    # Search native Twitch emotes\n",
    "    col_mask = emotes.isin([emote]).any()\n",
    "    cols = col_mask[col_mask == True].index.tolist()\n",
    "\n",
    "    # Search 3rd-party emotes\n",
    "    if len(cols) == 0:\n",
    "        if emote in bttv_emotes.values:\n",
    "            col_mask = bttv_emotes.isin([emote]).any()\n",
    "            cols = col_mask[col_mask == True].index.tolist()\n",
    "            print('BTTV:',cols)\n",
    "        if emote in ffz_emotes.values:\n",
    "            col_mask = ffz_emotes.isin([emote]).any()\n",
    "            cols = col_mask[col_mask == True].index.tolist()\n",
    "            print('FFZ:',cols)\n",
    "    else:\n",
    "        print(cols[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_channel('POGGERS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(':^)',[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Reconstruction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not implemented in Recommender.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def reconstruct_vec_from_3(word: str):\n",
    "    e = embeddings.most_similar(word,topn=3)\n",
    "    print(e)\n",
    "    # Get the vectors for the 3 most similar tokens\n",
    "    embed1 = embeddings[e[0][0]]\n",
    "    embed2 = embeddings[e[1][0]]\n",
    "    embed3 = embeddings[e[2][0]]\n",
    "\n",
    "    # A = reconstructed vector, B = ground truth\n",
    "    A = (embed1 + embed2 + embed3) / 3\n",
    "    B = embeddings[word]\n",
    "\n",
    "    # Compare reconstructed to actual vector\n",
    "    cos_sim = cosine_similarity(A.reshape(1, -1), B.reshape(1, -1))\n",
    "    print(cos_sim[0][0])\n",
    "    return cos_sim[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "reconstruct_emotes = []\n",
    "r = emotes[random.sample(list(emotes.columns),1)].sample(1).iloc[0][0]\n",
    "\n",
    "# Randomly reconstruct 400 emotes\n",
    "while len(reconstruct_emotes) < 400:\n",
    "    while (r != r) or (r.lower() in reconstruct_emotes) or (r not in embeddings): # r != r is a null check\n",
    "        r = emotes[random.sample(list(emotes.columns),1)].sample(1).iloc[0][0]\n",
    "    r = r.lower()\n",
    "    reconstruct_emotes.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = []\n",
    "for e in reconstruct_emotes:\n",
    "    try:\n",
    "        graph_data.append(reconstruct_vec_from_3(e))\n",
    "    except:\n",
    "        print(e,'not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reconstructed vector similarities\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Reconstruction Similarity of 400 Emotes')\n",
    "plt.xlim(0,1)\n",
    "\n",
    "plt.xlabel('Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(graph_data, color='Green',bins=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sample reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'WutFace'\n",
    "reconstruct_vec_from_3(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'LUL'\n",
    "reconstruct_vec_from_3(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'BabyRage'\n",
    "reconstruct_vec_from_3(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'aceofjam'\n",
    "reconstruct_vec_from_3(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3deea60006abea4783390f213adebd6836966db637e5dfe493c1abe5c82560f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
